---
title: "Prompt Caching -- Plan"
phase: Plan
date: "2026-02-07T14:30:00Z"
owner: "claude"
parent_research: "memory-bank/research/2026-02-07_prompt_caching.md"
git_commit_at_plan: "89c6e91"
tags: [plan, prompt-caching, cost-reduction]
---

## Goal

Add Anthropic-style prompt caching to tinyagent-v2 so the system prompt and
stable conversation prefix are not re-tokenized on every agent loop turn.

**Singular focus**: Inject `cache_control` breakpoints onto content blocks via
the existing `transform_context` hook, update the OpenRouter provider to
preserve them, and surface cache hit/miss metrics from provider responses.

**Non-goals**:
- Server-side caching (proxy/Alchemy internals are out of scope).
- Session-based caching via `session_id` (Anthropic uses content-block
  breakpoints, not session IDs; `session_id` remains dead code for now).
- Supporting non-Anthropic caching strategies (OpenAI, Gemini).

## Scope & Assumptions

### In scope
- Extend content block TypedDicts with optional `cache_control` field.
- Ship a built-in `transform_context` function that annotates the system prompt
  and the last user message with `cache_control: {"type": "ephemeral"}`.
- Update the OpenRouter provider to send structured content blocks (not flattened
  strings) when `cache_control` is present, and add the required
  `anthropic-beta: prompt-caching-2024-07-31` header.
- Parse `cache_creation_input_tokens` / `cache_read_input_tokens` from Anthropic
  responses and populate the existing `cacheRead` / `cacheWrite` counters.

### Out of scope
- Alchemy/Rust provider changes (raw dicts already pass through).
- Proxy provider changes (passthrough by design).
- Removing or refactoring `session_id` (separate cleanup ticket).

### Assumptions
- The primary LLM target is Anthropic Claude via OpenRouter.
- `cache_control` breakpoints on content blocks are the correct Anthropic
  caching mechanism (confirmed by Anthropic docs as of 2025).
- The `transform_context` hook is the right injection point because it runs
  before `convert_to_llm` and the default converter preserves extra dict keys.
- OpenRouter forwards Anthropic-specific headers and structured content blocks
  to the underlying Anthropic API.

## Deliverables (DoD)

| # | Artifact | Acceptance Criteria |
|---|----------|-------------------|
| D1 | `cache_control` field on `TextContent`, `ThinkingContent` | mypy passes; field is `Optional[dict]` with `total=False` |
| D2 | Built-in `add_cache_breakpoints()` transform function | Annotates system prompt + last user turn; exported from package |
| D3 | OpenRouter provider sends structured blocks | When any content block has `cache_control`, send `list[dict]` not `str` |
| D4 | OpenRouter sends `anthropic-beta` header | Header present when model string contains "anthropic" or "claude" |
| D5 | Cache usage stats populated | `cacheRead`/`cacheWrite` reflect actual API response values |

## Readiness (DoR)

- [x] Research doc complete and current (89c6e91, no drift)
- [x] Key files identified and analyzed
- [x] `tk` CLI available, existing tickets reviewed
- [ ] Anthropic prompt caching docs confirmed (knowledge gap: exact header name
      and response field names should be verified before implementation)

## Milestones

### M1: Type Foundation
Extend TypedDicts and options types with `cache_control` support.

### M2: Core Caching Logic
Build `add_cache_breakpoints()` transform function and wire it as an
optional default in `AgentOptions`.

### M3: Provider Passthrough
Update OpenRouter provider to preserve structured content blocks and
add the Anthropic beta header when caching is active.

### M4: Usage Metrics
Parse cache hit/miss token counts from API responses and populate
existing counter fields.

### M5: Verification
One integration-style test confirming cache_control blocks appear in
the outgoing request payload.

## Work Breakdown (Tasks)

### T1 -- Add `cache_control` to content block TypedDicts [M1]
**Summary**: Add optional `cache_control: dict[str, str] | None` field to
`TextContent` and `ThinkingContent` in `agent_types.py`.
**Owner**: TBD
**Estimate**: XS
**Dependencies**: None
**Acceptance Tests**:
- mypy passes with no new errors
- Existing code unchanged in behavior (field is optional, default absent)
**Files**: `tinyagent/agent_types.py`

### T2 -- Build `add_cache_breakpoints()` transform function [M2]
**Summary**: Create a function matching `TransformContextFn` signature that:
1. Wraps the system prompt content in a `TextContent` block with
   `cache_control: {"type": "ephemeral"}` if it is a plain string.
2. Annotates the last user message's final content block with
   `cache_control: {"type": "ephemeral"}`.
Export from a new `tinyagent/caching.py` module.
Add `enable_prompt_caching: bool` to `AgentOptions` that auto-wires this
as the `transform_context` callback when `True`.
**Owner**: TBD
**Estimate**: S
**Dependencies**: T1
**Acceptance Tests**:
- Given a 5-message history, only system prompt and last user message are annotated
- If user already supplies a `transform_context`, `enable_prompt_caching` composes
  (runs caching transform first, then user transform)
- Returns valid `list[AgentMessage]`
**Files**: `tinyagent/caching.py` (new), `tinyagent/agent.py`, `tinyagent/__init__.py`

### T3 -- OpenRouter: structured content blocks + beta header [M3]
**Summary**: Modify `_convert_user_message()` and `_convert_system_prompt()`
(if applicable) to emit `list[dict]` content (not flattened `str`) when any
content block contains `cache_control`. Add `anthropic-beta` header to
requests when model is Anthropic/Claude.
**Owner**: TBD
**Estimate**: M
**Dependencies**: T1
**Acceptance Tests**:
- When no `cache_control` present, behavior unchanged (string content)
- When `cache_control` present, content is `list[{"type":"text","text":"...","cache_control":{...}}]`
- `anthropic-beta: prompt-caching-2024-07-31` header present for Claude models
**Files**: `tinyagent/openrouter_provider.py`

### T4 -- Parse cache usage from API responses [M4]
**Summary**: In the OpenRouter provider's response parsing, extract
`cache_creation_input_tokens` and `cache_read_input_tokens` from the
usage object and surface them through the existing `cacheRead`/`cacheWrite`
fields in the usage dict and Rust `ModelCost`.
**Owner**: TBD
**Estimate**: S
**Dependencies**: T3
**Acceptance Tests**:
- When API response includes cache usage fields, they appear in usage stats
- When API response omits them, values remain 0 (backward compatible)
**Files**: `tinyagent/openrouter_provider.py`, `tinyagent/agent.py` (usage dict)

### T5 -- Verification test [M5]
**Summary**: One test that creates an `Agent` with `enable_prompt_caching=True`,
mocks the provider stream function, and asserts the outgoing `Context` contains
`cache_control` annotations on the expected content blocks.
**Owner**: TBD
**Estimate**: S
**Dependencies**: T2, T3
**Acceptance Tests**:
- Test passes with `pytest`
- Covers: system prompt annotation, last-user-message annotation, structured
  content block format
**Files**: `tests/test_caching.py` (new)

## Risks & Mitigations

| Risk | Impact | Likelihood | Mitigation | Trigger |
|------|--------|------------|------------|---------|
| OpenRouter does not forward `anthropic-beta` header | Caching silently fails (no cost savings, no errors) | Medium | Verify with a live API call early; fall back to direct Anthropic endpoint | No cache hits after first deploy |
| Anthropic changes caching header/field names | Build breaks or caching stops | Low | Pin to documented `prompt-caching-2024-07-31` beta; add version note | Anthropic deprecation notice |
| `transform_context` composition breaks user callbacks | User's custom transform overwritten | Medium | Compose transforms (cache first, user second) rather than replace | User reports lost transform |
| Content block flattening in other code paths | `cache_control` silently dropped | Medium | Grep for all `.join(` and string flattening of content blocks | Cache misses despite annotations |

## Test Strategy

One new test file (`tests/test_caching.py`) covering:
- `add_cache_breakpoints()` correctly annotates a message list
- OpenRouter structured block emission when `cache_control` is present
- Mock-based: no live API calls required

## References

- Research: `memory-bank/research/2026-02-07_prompt_caching.md`
- `tinyagent/agent_types.py` -- TypedDicts, Context, AgentLoopConfig
- `tinyagent/agent_loop.py:99-116` -- `_build_llm_context()` pipeline
- `tinyagent/agent.py:612-628` -- `_build_loop_context_and_config()`
- `tinyagent/openrouter_provider.py:69-117` -- content block conversion
- Anthropic prompt caching docs (external)

## Tickets Created (5 of 5)

| Ticket ID | Title | Priority | Status | Dependencies |
|-----------|-------|----------|--------|--------------|
| tv-0bae | Add cache_control field to content block TypedDicts | P1 | open | -- |
| tv-e14c | Build add_cache_breakpoints() transform function | P1 | open | tv-0bae |
| tv-a57a | OpenRouter: structured content blocks + anthropic-beta header | P2 | open | tv-0bae |
| tv-420f | Parse cache usage stats from Anthropic API responses | P2 | open | tv-a57a |
| tv-db5a | Verification test for prompt caching pipeline | P3 | open | tv-e14c, tv-a57a |

## Dependency Graph

```
tv-0bae (Type foundation)
  |
  +---> tv-e14c (Cache breakpoints transform)
  |       |
  +---> tv-a57a (OpenRouter provider update)
          |       |
          +---> tv-420f (Usage metrics parsing)
          |
  tv-e14c + tv-a57a ---> tv-db5a (Verification test)
```

## Ready to Start

- **tv-0bae** -- Add cache_control field to content block TypedDicts (P1, no blockers)
